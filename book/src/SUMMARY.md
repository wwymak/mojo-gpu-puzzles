# Summary

# Getting Started
- [ğŸ”¥ Introduction](./introduction.md)
- [ğŸ§­ Puzzles Usage Guide](./howto.md)

# Part I: GPU Fundamentals
- [Puzzle 1: Map](./puzzle_01/puzzle_01.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_01/raw.md)
  - [ğŸ’¡ Preview: Modern Approach with LayoutTensor](./puzzle_01/layout_tensor_preview.md)
- [Puzzle 2: Zip](./puzzle_02/puzzle_02.md)
- [Puzzle 3: Guards](./puzzle_03/puzzle_03.md)
- [Puzzle 4: 2D Map](./puzzle_04/puzzle_04.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_04/raw.md)
  - [ğŸ“š Learn about LayoutTensor](./puzzle_04/introduction_layout_tensor.md)
  - [ğŸš€ Modern 2D Operations](./puzzle_04/layout_tensor.md)
- [Puzzle 5: Broadcast](./puzzle_05/puzzle_05.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_05/raw.md)
  - [ğŸ“ LayoutTensor Version](./puzzle_05/layout_tensor.md)
- [Puzzle 6: Blocks](./puzzle_06/puzzle_06.md)
- [Puzzle 7: 2D Blocks](./puzzle_07/puzzle_07.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_07/raw.md)
  - [ğŸ“ LayoutTensor Version](./puzzle_07/layout_tensor.md)
- [Puzzle 8: Shared Memory](./puzzle_08/puzzle_08.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_08/raw.md)
  - [ğŸ“ LayoutTensor Version](./puzzle_08/layout_tensor.md)

# Part II: ğŸ§® GPU Algorithms
- [Puzzle 9: Pooling](./puzzle_09/puzzle_09.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_09/raw.md)
  - [ğŸ“ LayoutTensor Version](./puzzle_09/layout_tensor.md)
- [Puzzle 10: Dot Product](./puzzle_10/puzzle_10.md)
  - [ğŸ”° Raw Memory Approach](./puzzle_10/raw.md)
  - [ğŸ“ LayoutTensor Version](./puzzle_10/layout_tensor.md)
- [Puzzle 11: 1D Convolution](./puzzle_11/puzzle_11.md)
  - [ğŸ”° Simple Version](./puzzle_11/simple.md)
  - [â­ Block Boundary Version](./puzzle_11/block_boundary.md)
- [Puzzle 12: Prefix Sum](./puzzle_12/puzzle_12.md)
  - [ğŸ”° Simple Version](./puzzle_12/simple.md)
  - [â­ Complete Version](./puzzle_12/complete.md)
- [Puzzle 13: Axis Sum](./puzzle_13/puzzle_13.md)
- [Puzzle 14: Matrix Multiplication (MatMul)](./puzzle_14/puzzle_14.md)
    - [ğŸ”° NaÃ¯ve Version with Global Memory](./puzzle_14/naÃ¯ve.md)
    - [ğŸ“š Learn about Roofline Model](./puzzle_14/roofline.md)
    - [ğŸ¤ Shared Memory Version](./puzzle_14/shared_memory.md)
    - [ğŸ“ Tiled Version](./puzzle_14/tiled.md)

# Part III: ğŸ Interfacing with Python via MAX Graph Custom Ops
- [Puzzle 15: 1D Convolution Op](./puzzle_15/puzzle_15.md)
- [Puzzle 16: Softmax Op](./puzzle_16/puzzle_16.md)
- [Puzzle 17: Attention Op](./puzzle_17/puzzle_17.md)
- [ğŸ¯ Bonus Challenges](./bonuses/part3.md)

# Part IV: ğŸ”¥ PyTorch Custom Ops Integration
- [Puzzle 18: 1D Convolution Op](./puzzle_18/puzzle_18.md)
- [Puzzle 19: Embedding Operations](./puzzle_19/puzzle_19.md)
  - [ğŸ”° Simple Embedding Kernel](./puzzle_19/simple_embedding_kernel.md)
  - [âš¡ Memory Access Patterns](./puzzle_19/coelased_memory_patterns.md)
  - [ğŸ“Š Performance Comparison](./puzzle_19/performance.md)

- [Puzzle 20: Autograd Integration](./puzzle_20/puzzle_20.md)
  - [ğŸ”„ Forward Pass Implementation](./puzzle_20/forward_pass.md)
  - [ğŸ“ Backward Pass Implementation](./puzzle_20/backward_pass.md)
  - [ğŸ§® Custom Function Pattern](./puzzle_20/custom_function.md)

# Part V: ğŸŒŠ Mojo Functional Patterns and Benchmarking
- [Puzzle 20: GPU Functional Programming Patterns]() # TODO
  - [elementwise - Basic GPU Functional Operations](./puzzle_20/elementwise.md)
  - [tile - Memory-Efficient Tiled Processing](./puzzle_20/tile.md)
  - [Vectorization - SIMD Control](./puzzle_20/vectorize.md)
  - [ğŸ§  GPU Threading vs SIMD Concepts](./puzzle_20/gpu-thread-vs-simd.md)
  - [ğŸ“Š Benchmarking in Mojo](./puzzle_20/benchmarking.md)

# Part VI: âš¡ Warp-Level Programming
- [Puzzle 21: Warp Fundamentals](./puzzle_21/puzzle_21.md)
  - [Warp lanes & SIMT execution](./puzzle_21/warp_simt.md)
  - [warp.sum() Essentials](./puzzle_21/warp_sum.md)
  - [ğŸ“Š When to Use Warp Programming](./puzzle_21/warp_extra.md)
- [Puzzle 22: Essential Warp Operations]()
  - [ğŸ”„ warp.shuffle_down() Communication]()
  - [ğŸ”€ warp.shuffle_xor() Butterfly Patterns]()
  - [ğŸ“¡ warp.broadcast() Distribution]()
- [Puzzle 23: Advanced Warp Patterns]()
  - [ğŸ§® warp.prefix_sum() Scan Operations]()
  - [lane_group_* Sub-warp Operations]()
  - [Combining with Functional Patterns]()
- [ğŸ“‹ Quick Reference: Essential Warp Operations]()

# Part VII: ğŸ§  Advanced Memory Operations
- [Puzzle 24: Memory Coalescing]()
  - [ğŸ“š Understanding Coalesced Access]()
  - [Optimized Access Patterns]()
  - [ğŸ”§ Troubleshooting Memory Issues]()
- [Puzzle 25: Async Memory Operations]()
- [Puzzle 26: Memory Fences & Atomics]()
- [Puzzle 27: Prefetching & Caching]()

# Part VIII: ğŸ“Š Performance Analysis & Optimization
- [Puzzle 28: GPU Profiling Basics]()
- [Puzzle 29: Occupancy Optimization]()
- [Puzzle 30: Bank Conflicts]()
  - [ğŸ“š Understanding Shared Memory Banks]()
  - [Conflict-Free Patterns]()

# Part IX: ğŸš€ Advanced GPU Features
- [Puzzle 31: Tensor Core Operations]()
- [Puzzle 32: Random Number Generation]()
- [Puzzle 33: Advanced Synchronization]()

# Part X: ğŸŒ Multi-GPU & Advanced Applications
- [Puzzle 34: Multi-Stream Programming]()
- [Puzzle 35: Multi-GPU Basics]()
- [Puzzle 36: End-to-End Optimization Case Study]()
- [ğŸ¯ Advanced Bonus Challenges]()
